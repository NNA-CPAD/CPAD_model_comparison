{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Supporting Functions for Func4ModelComparison**"],"metadata":{"id":"UBWwJ7YToo5r"}},{"cell_type":"markdown","source":["### Function to Match Times\n","**Description:** Matches temporal extent and resolution of two datasets.  \n","**Input Data:** Observational data and climate model data with the same temporal resolution (hourly, daily, monthly, etc.) that have already been compressed down to one file using the Script4DataExtraction notebook or python script.  \n","**Output Data:** Observational data and climate model data with matching time dimensions (same start and end dates as well as same length).  \n","**Process:**  \n","1. Matches the start times of the data by determining which dataset has the earlier first date and selecting only the data from that dataset beginning on the first date of the dataset with the later first date.  \n","2. Matches the end times of the data by determining which dataset has the later last date and selecting only the data from that dataset from the beginning until the last date of the dataset with the earlier last date. *At this point both datasets should have the same start and end date but may still be different lengths if one of them includes leap days while the other does not.*  \n","3. Address leapday differences checking if the length of the time dimension for both datasets is the same. If it is, the two datasets have been successfully time corrected and are renamed to reflect this new status. Otherwise, the length of the time dimension of the two datasets is not the same, leap days (Feb 29) are removed from the longer of the two datasets.\n","4. The time-corrected datasets are returned by the time-matching function.  "],"metadata":{"id":"0Bu3d7mZoW_H"}},{"cell_type":"code","source":["def time_match(obs_data, clim_data, time_type):\n","  #convert to same time index\n","  if type(clim_data.indexes['time']) != pd.core.indexes.datetimes.DatetimeIndex:\n","    clim_data['time'] = clim_data.indexes['time'].to_datetimeindex()\n","  if type(obs_data.indexes['time']) != pd.core.indexes.datetimes.DatetimeIndex:\n","    obs_data['time'] = obs_data.indexes['time'].to_datetimeindex()\n","\n","  clim_data['time'] = pd.to_datetime(clim_data.time.dt.strftime(time_type).values, format = time_type)\n","  obs_data['time'] = pd.to_datetime(obs_data.time.dt.strftime(time_type).values, format = time_type)\n","\n","  # 1) match start times--------------------------------------------------------\n","  if np.where(obs_data.time == clim_data.time[0])[0].size > 0:\n","    obs_start = np.where(obs_data.time == clim_data.time[0])[0][0]\n","    obs_data = obs_data.isel(time=np.arange(obs_start, len(obs_data.time), 1))\n","  elif np.where(clim_data.time == obs_data.time[0])[0].size > 0:\n","    clim_start = np.where(clim_data.time == obs_data.time[0])[0][0]\n","    clim_data = clim_data.isel(time=np.arange(clim_start, len(clim_data.time), 1))\n","\n","  # 2) match end times----------------------------------------------------------\n","  if np.where(obs_data.time == clim_data.time[-1])[0].size > 0:\n","    obs_end = np.where(obs_data.time == clim_data.time[-1])[0][0]\n","    obs_data = obs_data.isel(time=np.arange(0, obs_end + 1, 1))\n","  elif np.where(clim_data.time == obs_data.time[-1])[0].size > 0:\n","    clim_end = np.where(clim_data.time == obs_data.time[-1])[0][0]\n","    clim_data = clim_data.isel(time=np.arange(0, clim_end + 1, 1))\n","\n","  # 3) address leap year differences--------------------------------------------\n","  if len(obs_data.time) > len(clim_data.time):\n","    obs_data = obs_data.sel(time=~((obs_data.time.dt.month == 2) & (obs_data.time.dt.day == 29)))\n","  elif len(clim_data.time) > len(obs_data.time):\n","    clim_data = clim_data.sel(time=~((clim_data.time.dt.month == 2) & (clim_data.time.dt.day == 29)))\n","\n","  # 4) return time-corrected data-----------------------------------------------\n","  return obs_data, clim_data"],"metadata":{"id":"CZHWcOtBmIwz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Function to Match Lat, Lon Coords\n","**Description:** Matches spatial extent and resolution of two datasets that already have the same temporal extent and resolution.  \n","**Input Data:** Observational data and climate model data that has already been time-corrected after being passed through the time-match function.  \n","**Output Data:** Observational data and climate data that have the same time extent, spatial extent, and resolution, and are ready for analysis.  \n","**Process:**  \n","1. Sort data by ascending latitude in preparation for matching latitudes.\n","2. Matches starting latitude by:\n","    * Determining which latitude in each dataset is closest to the lowest latitude in the other dataset, call this the starting latitude.\n","    * If the starting latitude of a given dataset is not the same as the lowest latitude in its own dataset, select only the data from the starting latitude upward in that dataset.   \n","3. Matches ending latitude by:\n","    * Determining which latitude in each dataset is closest to the highest latitude in the other dataset, call this the ending latitude.\n","    * If the ending latitude of a given dataset is not the same as the last latitude in that dataset, select only the data from the first latitude in that dataset (as adjusted by step 1) until the ending latitude.  \n","4. Matches starting longitude by:\n","    * Determining which longitude in each dataset is closest to the lowest lowest longitude in the other dataset, call this the starting longitude.\n","    * If the starting longitude of a given dataset is not the same as the lowest longitude in its own dataset, select only the data from the starting longitude upward in that dataset.  \n","5. Matches ending longitude by:\n","    * Determining which longitude in each dataset is closest to the highest longitude in the other dataset, call this the ending longitude.\n","    * If the ending longitude of a given dataset is not the same as the last longitude in that dataset, select only the data from the first longitude in that dataset (as adjusted by step 5) until the ending longitude.   \n","6. Addresses differences in spatial resolution by:\n","    * Checking if the length of the latitude variable is the same for each dataset.\n","    * If not, determine which dataset has lower resolution and select only the data from the higher resolution dataset that are at the grid points of the points for the lower resolution dataset. In places where there is not an exact grid point match, choose the nearest grid point.   "],"metadata":{"id":"4jcN0aUvoZAf"}},{"cell_type":"code","source":["def space_match(obs_data_tc, clim_data_tc):  # get all input vars from output of time_match()\n","    # 1) sort by ascending lats------------------------------------------------\n","    obs_data_tc = obs_data_tc.sortby('lat', ascending=True)\n","    clim_data_tc = clim_data_tc.sortby('lat', ascending=True)\n","\n","    # 2) match start lats------------------------------------------------------\n","    obs_lat_start = obs_data_tc.sel(lat=clim_data_tc.lat[0], method='nearest').lat\n","    clim_lat_start = clim_data_tc.sel(lat=obs_data_tc.lat[0], method='nearest').lat\n","\n","    if np.where(obs_data_tc.lat == obs_lat_start)[0][0] > 0:\n","        obs_lat_start_i = np.where(obs_data_tc.lat == obs_lat_start)[0][0]\n","        obs_data_tc = obs_data_tc.isel(lat=np.arange(obs_lat_start_i, len(obs_data_tc.lat), 1))\n","    elif np.where(clim_data_tc.lat == clim_lat_start)[0][0] > 0:\n","        clim_lat_start_i = np.where(clim_data_tc.lat == clim_lat_start)[0][0]\n","        clim_data_tc = clim_data_tc.isel(lat=np.arange(clim_lat_start_i, len(clim_data_tc.lat), 1))\n","\n","    # 3) match end lats--------------------------------------------------------\n","    obs_lat_end = obs_data_tc.sel(lat=clim_data_tc.lat[-1], method='nearest').lat\n","    clim_lat_end = clim_data_tc.sel(lat=obs_data_tc.lat[-1], method='nearest').lat\n","\n","    if obs_data_tc.lat[np.where(obs_data_tc.lat == obs_lat_end)[0][0]] != obs_data_tc.lat[-1]:\n","        obs_lat_end_i = np.where(obs_data_tc.lat == obs_lat_end)[0][0]\n","        obs_data_tc = obs_data_tc.isel(lat=np.arange(0, obs_lat_end_i, 1))\n","    elif clim_data_tc.lat[np.where(clim_data_tc.lat == clim_lat_end)[0][0]] != clim_data_tc.lat[-1]:\n","        clim_lat_end_i = np.where(clim_data_tc.lat == clim_lat_end)[0][0]\n","        clim_data_tc = clim_data_tc.isel(lat=np.arange(0, clim_lat_end_i, 1))\n","\n","    # 4) match start lons------------------------------------------------------\n","    obs_lon_start = obs_data_tc.sel(lon=clim_data_tc.lon[0], method='nearest').lon\n","    clim_lon_start = clim_data_tc.sel(lon=obs_data_tc.lon[0], method='nearest').lon\n","\n","    if np.where(obs_data_tc.lon == obs_lon_start)[0][0] > 0:\n","        obs_lon_start_i = np.where(obs_data_tc.lon == obs_lon_start)[0][0]\n","        obs_data_tc = obs_data_tc.isel(lon=np.arange(obs_lon_start_i, len(obs_data_tc.lon), 1))\n","    elif np.where(clim_data_tc.lon == clim_lon_start)[0][0] > 0:\n","        clim_lon_start_i = np.where(clim_data_tc.lon == clim_lon_start)[0][0]\n","        clim_data_tc = clim_data_tc.isel(lon=np.arange(clim_lon_start_i, len(clim_data_tc.lon), 1))\n","\n","    # 5) match end lons--------------------------------------------------------\n","    obs_lon_end = obs_data_tc.sel(lon=clim_data_tc.lon[-1], method='nearest').lon\n","    clim_lon_end = clim_data_tc.sel(lon=obs_data_tc.lon[-1], method='nearest').lon\n","\n","    if obs_data_tc.lon[np.where(obs_data_tc.lon == obs_lon_end)[0][0]] != obs_data_tc.lon[-1]:\n","        obs_lon_end_i = np.where(obs_data_tc.lon == obs_lon_end)[0][0]\n","        obs_data_tc = obs_data_tc.isel(lon=np.arange(0, obs_lon_end_i, 1))\n","    elif clim_data_tc.lon[np.where(clim_data_tc.lon == clim_lon_end)[0][0]] != clim_data_tc.lon[-1]:\n","        clim_lon_end_i = np.where(clim_data_tc.lon == clim_lon_end)[0][0]\n","        clim_data_tc = clim_data_tc.isel(lon=np.arange(0, clim_lon_end_i, 1))\n","\n","    # 6) address differences in spatial resolution -- currently just downselecting to resolution of lowest resolution data\n","    if len(obs_data_tc.lat) != len(clim_data_tc.lat):\n","        if len(obs_data_tc.lat) > len(clim_data_tc.lat):\n","            obs_data_tc = obs_data_tc.sel(lat = clim_data_tc.lat.values, lon = clim_data_tc.lon.values, method = 'nearest')\n","            obs_data_tc['lat'] = clim_data_tc.lat\n","            obs_data_tc['lon'] = clim_data_tc.lon\n","\n","        elif len(clim_data_tc.lat) > len(obs_data_tc.lat):\n","            clim_data_tc = obs_data_tc.sel(lat = obs_data_tc.lat.values, lon = obs_data_tc.lon.values, method = 'nearest')\n","            clim_data_tc['lat'] = obs_data_tc.lat\n","            clim_data_tc['lon'] = obs_data_tc.lon\n","\n","    return(obs_data_tc, clim_data_tc)"],"metadata":{"id":"Q658ZCURcXKr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Function to Mask Out Ocean/Land\n","**Description:** Creates 4 new data files corresponding to the observational data with the ocean masked out (obs_land), the observational data with the land masked out (obs_ocean), the climate model data with the ocean masked out (clim_land), and the climate model data with the land masked out (clim_ocean).  \n","**Input Data:** Observational and climate model data that has already been corrected for differences in temporal and spatial extent and resolution using the time_match() and space_match() functions respectively.\n","**Output Data:**  \n","1. obs_land -- observational data with the ocean masked out (only contains land points, everything else is NaN)  \n","2. obs_ocean -- observational data with the land masked out (only contains ocean points, everything else is NaN)  \n","3. clim_land -- climate model data with the ocean masked out (only contains land points, everything else is NaN)  \n","4. clim_ocean -- climate model data with the land masked out (only contains ocean points, everything else is NaN)  \n","**Process:**  \n","1. Converts mask longitude coordinates to long1 to match observational and climate data for analysis.  \n","2. Matches mask coordinates to data coordinates by:  \n","    * creating empty mask array with same lat, lon dimensions as observational data (which should also be the same as for the climate model data by virtue of using the space_match() function).  \n","    * for each lat, lon point in the observational data (which should be the same as the lat, lon points in the climate model data), find the indices of the nearest latitude and longitude in the mask data and select the mask data point corresponding to those lat, lon indices.  \n","3. Convert new matched mask back to xarray DataArray  \n","4. Create separate masks for the ocean and the land by:  \n","    * finding the coordinates where the coordinate-matched mask is zero (this corresponds to the ocean) and where it is one (this corresponds to the land).  \n","    * creating new mask files for both masking out the ocean (ocean_mask) and masking out the land (land_mask) with the same dimensions as the coordinate-matched mask.  \n","    * for the ocean mask, in every place where the coordinate-matched mask is 0, replace the corresponding point in the ocean mask with a NaN, in every place where the coordinate-matched mask is 1, replace the corresponding point in the ocean mask with 1.  \n","    * for the land mask, in every place where the coordinate-matched mask is 0, replace the corresponding point in the ocean mask with 1, in every place where the coordinate-matched mask is 1, replace the corresponding point in the land mask with a NaN.  \n","5. Create masked datasets for the observational and climate model data by:  \n","    * For both the climate model data and the observational data, create 2 new arrays of zeros with the same dimensions as the original data (in total should have 4 new arrays of zeros).  \n","    * for each time in the observational and climate model data, multiply the observational data by each mask separately (land_mask and ocean_mask), and store in the new arrays.  \n","6. Return the masked datasets."],"metadata":{"id":"4OvtAsqpoe7K"}},{"cell_type":"code","source":["def mask_fun(obs_data_analysis, clim_data_analysis, mask, lon_type = 'long3'):\n","\n","  #convert mask dimensions from ni and nj to lon and lat\n","  mask['ni'] = mask.xc.sel(nj = 0).values\n","  mask['nj'] = mask.yc.sel(ni = 0).values\n","\n","  mask = mask.rename({'nj': 'lat', 'ni': 'lon'}).drop(['xc','yc'])\n","\n","  if lon_type == 'long3':\n","    mask['lon'] = (mask.lon + 180) % 360 - 180\n","    mask = mask.sortby('lon')\n","\n","  #create two separate masks, one where ocean is 1 and land is nan, other where land is 1 and ocean is nan\n","  ocean_mask = (mask.where(mask == 0, other = np.nan)+1).sel(lat = obs_data_analysis.lat.values, lon = obs_data_analysis.lon.values, method = 'nearest').expand_dims(time = obs_data_analysis.time)\n","  ocean_mask['lat'] = obs_data_analysis.lat\n","  ocean_mask['lon'] = obs_data_analysis.lon\n","  ocean_mask = ocean_mask.rename('ocean_mask')\n","\n","  land_mask = mask.where(mask != 0, other = np.nan).sel(lat = obs_data_analysis.lat.values, lon = obs_data_analysis.lon.values, method = 'nearest').expand_dims(time = obs_data_analysis.time)\n","  land_mask['lat'] = obs_data_analysis.lat\n","  land_mask['lon'] = obs_data_analysis.lon\n","  land_mask  = land_mask.rename('land_mask')\n","\n","  #apply ocean and land masks to observational and climate data\n","  obs_land = obs_data_analysis * land_mask\n","  obs_land = obs_land.rename('obs_land')\n","  obs_ocean = obs_data_analysis * ocean_mask\n","  obs_ocean = obs_ocean.rename('obs_ocean')\n","  clim_land = clim_data_analysis * land_mask\n","  clim_land = clim_land.rename('clim_land')\n","  clim_ocean = clim_data_analysis * ocean_mask\n","  clim_ocean = clim_ocean.rename('clim_ocean')\n","\n","  #return the masked datasets\n","  return(obs_land, obs_ocean, clim_land, clim_ocean)"],"metadata":{"id":"tgOS4yENcaHS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Function to Compare Model with Observations\n","**Input Data:**  Observational data and climate model data that has already been corrected for differences in temporal and spatial extent and resolution using the time_match() and space_match() functions respectively.  \n","**Outputs:**  \n","* \"AvgDifMap\" -- Map plot of difference between the climate model and the observational data for the variable of interest averaged over the full temporal extent of the data.\n","* \"TwoHist\" -- Plot of histograms of data values for both the model and observational data.  \n","* \"DifHist\" -- Histogram of the values of the difference between the climate model and observational data.  \n","* Summary Statistics -- mean, standard deviation, min, and max for each dataset as well as the difference between the two datasets, mean squared error, root mean squared error.  \n","* T-test -- test-statistic and p-value for one-sample t-test to determine if mean of difference is statistically different than 0.  \n","* F-test -- test statistic and p-value for F-test to determine if variances of observational data and climate data are statistically different from each other for full data, spatial variance only, and temporal variance only.\n","\n","**Process:**  \n","1. Finds difference between model data and observations.  \n","2. Plots difference averaged over all time by:\n","    * Checks if longitude coordinates are continuous.  \n","    * If coordinates are continuous, plot as usual.\n","    * Otherwise, coordinates are discontinuous (i.e. crosses 180 lon without covering the whole globe), use a plot with 180 as the central longitude instead of 0.   \n","3. Plots histogram of each distribution (climate model data and observational data).  \n","4. Plots histogram of the differences between climate model data and observational data with a vertical line at zero.  \n","5. Plots timeseries of spatial mean of each distribution (climate model and observational data).  \n","6. Plots timeseries of spatial mean of difference between climate model and observational data with a horizontal line at zero.  \n","7. Calculates summary statistics (mean , standard deviation, minimum, and maximum) for each of the observational data, climate model data, and their differences.  \n","8. Performs a T-test to determine if the mean of the differences is statistically different than 0, indicating that the two populations (climate model data and observational data) have statistically different means.  \n","9. Performs three F-tests to determine if the internal variability of each of the climate model and observational datasets are statistically different for:  \n","    * the datasets as a whole  \n","    * spatial variability only  \n","    * temporal variability only  \n","10. Calculates the mean squared error and root mean squared error."],"metadata":{"id":"ad9z7RNRoiP5"}},{"cell_type":"code","source":["def plot_compare(obs_data_analysis, clim_data_analysis, data_type, out_path):\n","    # 1) difference between model and observations\n","    dif = clim_data_analysis - obs_data_analysis\n","\n","    # 2) plot difference averaged over all time in data------------------------\n","    dif_avg = dif.mean(dim='time')\n","\n","    lon_step = dif_avg.lon[2] - dif_avg.lon[1]\n","    lon_min = min(dif_avg.lon)\n","    lon_max = max(dif_avg.lon)\n","    lev1 = np.arange(-5, 5.1, 0.1)  # change to your levels\n","    cmap1 = plt.cm.RdBu_r\n","    if (lon_max - lon_min + lon_step)/lon_step == len(dif_avg.lon):  # check if␣longitudes are continuous, if there is no gap plot across as usual (central longitude = 0)\n","        plt.figure(figsize=(15, 5))\n","        ax1 = plt.axes(projection=ccrs.PlateCarree())\n","        dif_avg.plot.contourf(ax=ax1, transform=ccrs.PlateCarree(), cmap=cmap1, levels=lev1, extend='both')\n","        ax1.coastlines()\n","        plt.title('Average Difference Between Model and Observations')\n","        plt.savefig(os.path.join(out_path, data_type+'_AvgDifMap'))\n","        plt.show()\n","    else:  # if longitudes are not continuous, plot with 180 as central longitude instead\n","      new_dif_lon = np.zeros(len(dif_avg.lon))\n","      for i in range(0, len(dif_avg.lon)):\n","        if dif_avg.lon[i] < 0:\n","          new_dif_lon[i] = dif_avg.lon[i] % 180\n","        else:\n","          new_dif_lon[i] = dif_avg.lon[i] - 180\n","      dif_avg['lon'] = new_dif_lon\n","      cm = 180\n","      proj = ccrs.PlateCarree(central_longitude=cm)\n","      fig = plt.figure(figsize = [20,5])\n","      ax1 = fig.add_subplot(3, 1, 3, projection=proj)\n","      dif_avg.plot.contourf(ax=ax1, cmap=cmap1, levels=lev1, extend='both')\n","      ax1.text(35,85,f'Diff Mean: {dif_mean:.2e}')\n","      ax1.text(35,80, f'Diff Std: {dif_stdev:.2e}')\n","      ax1.text(35,75, f'Diff Min: {dif_min:.2e}')\n","      ax1.text(35,70, f'Diff Max: {dif_max:.2e}')\n","      ax1.coastlines()\n","      ax1.gridlines(draw_labels=True, crs=ccrs.PlateCarree())\n","      plt.title('Average Difference Between Model and Observations: {}'.format(var_name))\n","\n","\n","      new_clim_lon = np.zeros(len(clim_data_mean.lon))\n","      for i in range(0, len(clim_data_mean.lon)):\n","        if clim_data_mean.lon[i] < 0:\n","          new_clim_lon[i] = clim_data_mean.lon[i] % 180\n","        else:\n","          new_clim_lon[i] = clim_data_mean.lon[i] - 180\n","      clim_data_mean['lon'] = new_clim_lon\n","      cm = 180\n","      proj = ccrs.PlateCarree(central_longitude=cm)\n","      fig = plt.figure(figsize = [20,5])\n","      ax2 = fig.add_subplot(3, 1, 2, projection=proj)\n","      clim_data_mean.plot.contourf(ax=ax2, cmap=cmap1, levels=lev2, extend='both')\n","      ax2.text(35,85,f'Model Mean: {clim_mean:.2e}')\n","      ax2.text(35,80, f'Model Std: {clim_stdev:.2e}')\n","      ax2.coastlines()\n","      ax2.gridlines(draw_labels=True, crs=ccrs.PlateCarree())\n","      plt.title('Average Model Field: {}'.format(var_name))\n","\n","      new_obs_lon = np.zeros(len(obs_data_mean.lon))\n","      for i in range(0, len(obs_data_mean.lon)):\n","        if obs_data_mean.lon[i] < 0:\n","          new_obs_lon[i] = obs_data_mean.lon[i] % 180\n","        else:\n","          new_obs_lon[i] = obs_data_mean.lon[i] - 180\n","      obs_data_mean['lon'] = new_obs_lon\n","      cm = 180\n","      proj = ccrs.PlateCarree(central_longitude=cm)\n","      fig = plt.figure(figsize = [20,5])\n","      ax3 = fig.add_subplot(3, 1, 1, projection=proj)\n","      obs_data_mean.plot.contourf(ax=ax3, cmap=cmap1, levels=lev2, extend='both')\n","      ax3.text(35,85,f'Obs Mean: {obs_mean:.2e}')\n","      ax3.text(35,80, f'Obs Std: {obs_stdev:.2e}')\n","      ax3.coastlines()\n","      ax3.gridlines(draw_labels=True, crs=ccrs.PlateCarree())\n","      plt.title('Average Observation Field: {}'.format(var_name))\n","      plt.savefig(os.path.join(out_path, data_type+'_AvgDifMap'))\n","      plt.show()\n","\n","\n","    # 3) plot histogram of each------------------------------------------------\n","    plt.figure(figsize=(9, 5))\n","    clim_data_analysis.plot.hist(bins=10000, color='r', alpha=0.5, label='Model Data')\n","    obs_data_analysis.plot.hist(bins=10000, color='k', alpha=0.5, label='Observational Data')\n","    plt.legend()\n","    plt.ylabel('Count')\n","    plt.title('Distribution of Model Predictions vs Observations')\n","    #plt.xlim([-0.001, 0.1])   #----- add x-axis limits if desired\n","    #plt.ylim([0, 2*10**6])\n","    plt.savefig(os.path.join(out_path, data_type+'_2Hist'))\n","    plt.show()\n","\n","    # 4) plot histogram of differences-----------------------------------------\n","    plt.figure(figsize=(9, 5))\n","    dif.plot.hist(bins=10000, color='b', alpha = 0.5, label = 'Data')\n","    plt.axvline(x = 0, color = 'r', alpha = 0.5, label = 'Zero')\n","    plt.legend()\n","    plt.ylabel('Count')\n","    plt.title('Distribution of Differences Between Model Predictions and Observations')\n","    #plt.xlim([-0.1, 0.1])   #----- add x-axis limits if desired\n","    #plt.ylim([0, 0.6*10**6])\n","    plt.savefig(os.path.join(out_path, data_type+'_DifHist'))\n","    plt.show()\n","\n","    # 5) plot timeseries of each\n","    obs_ts = obs_data_analysis.mean(dim='lat').mean(dim='lon')\n","    clim_ts = clim_data_analysis.mean(dim='lat').mean(dim='lon')\n","    plt.figure(figsize=(15, 10))\n","    obs_ts.plot(color='b', alpha=0.5, label='Observational Data Mean')\n","    clim_ts.plot(color='r', alpha=0.5, label='Climate Model Data Mean')\n","    plt.legend()\n","    plt.title('Timeseries of Mean for Climate Model and Observational Data')\n","    plt.savefig(os.path.join(out_path, data_type+'_2TS'))\n","    plt.show()\n","\n","    # 6) plot timeseries of difference\n","    dif_ts = (clim_data_analysis - obs_data_analysis).mean(dim='lat').mean(dim='lon')\n","    plt.figure(figsize=(15,10))\n","    dif_ts.plot(color='b', label='Data')\n","    plt.axhline(y=0, color='r', label='Zero')\n","    plt.title('Timeseries of Difference Between Climate Model and Observational Data')\n","    plt.savefig(os.path.join(out_path, data_type+'_DifTS'))\n","    plt.show()\n","\n","    # 7) print summary statistics of each dataset------------------------------\n","    obs_mean = float(obs_data_analysis.mean())  # save mean and stdev for use in calculating test statistics\n","    obs_stdev = float(obs_data_analysis.std())\n","    obs_min = np.amin(obs_data_analysis)\n","    obs_max = np.amax(obs_data_analysis)\n","\n","    clim_mean = float(clim_data_analysis.mean())\n","    clim_stdev = float(clim_data_analysis.std())\n","    clim_min = np.amin(clim_data_analysis)\n","    clim_max = np.amax(clim_data_analysis)\n","\n","    dif_mean = float(dif.mean())\n","    dif_stdev = float(dif.std())\n","    dif_min = np.amin(dif)\n","    dif_max = np.amax(dif)\n","\n","    # 8) T-test to determine if difference is different than 0-----------------\n","    n = len(dif.lat) * len(dif.lon) * len(dif.time)\n","    T_stat = (dif_mean - 0)/(dif_stdev/np.sqrt(n))\n","    T_p_val = stats.t.sf(abs(T_stat), n-1)\n","\n","    # 9) F-test to detemine if variances are statistically different from each other\n","    obs_var_full = float(obs_data_analysis.var(skipna=True))\n","    clim_var_full = float(clim_data_analysis.var(skipna=True))\n","    obs_var_space = float((obs_data_analysis.mean(dim='time').std())**2)\n","    clim_var_space = float((clim_data_analysis.mean(dim='time').std())**2)\n","    obs_var_time = obs_data_analysis.var(dim='time', skipna=True)\n","    clim_var_time = clim_data_analysis.var(dim='time', skipna=True)\n","    obs_var_time_avg = float(obs_var_time.mean())\n","    clim_var_time_avg = float(clim_var_time.mean())\n","\n","    obs_n_full = float(obs_data_analysis.count())\n","    clim_n_full = float(clim_data_analysis.count())\n","    obs_n_space = float(obs_data_analysis.mean(dim='time').count())\n","    clim_n_space = float(clim_data_analysis.mean(dim='time').count())\n","    obs_n_time = float(obs_data_analysis.time.count())\n","    clim_n_time = float(clim_data_analysis.time.count())\n","\n","    F_stat_full = obs_var_full/clim_var_full\n","    F_p_val_full = 1-stats.f.cdf(F_stat_full, obs_n_full-1, clim_n_full-1)\n","    F_stat_space = obs_var_space/clim_var_space\n","    F_p_val_space = 1-stats.f.cdf(F_stat_space, obs_n_space-1, clim_n_space-1)\n","    F_stat_time = obs_var_time_avg/clim_var_time_avg\n","    F_p_val_time = 1-stats.f.cdf(F_stat_time, obs_n_time-1, clim_n_time-1)\n","\n","    # 10) Find mean squared error-----------------------------------------------\n","    mse = float(np.square(np.subtract(obs_data_analysis, clim_data_analysis)).mean())\n","    rmse = np.sqrt(mse)\n","\n","    return(obs_mean, obs_stdev, obs_min, obs_max, obs_var_full, obs_var_space, obs_var_time_avg,\n","           clim_mean, clim_stdev, clim_min, clim_max, clim_var_full, clim_var_space, clim_var_time_avg,\n","           dif_mean, dif_stdev, dif_min, dif_max,\n","           mse, rmse,\n","           F_stat_full, F_stat_space, F_stat_time, F_p_val_full, F_p_val_space, F_p_val_time,\n","           T_stat, T_p_val)"],"metadata":{"id":"TF5kX75JcfZb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Advanced Plotting Function\n","Same process as regular plotting function but with better color map bounds, mean statistics displayed beside map plots, and rounded statistics in the final table."],"metadata":{"id":"Mw3oBJUjQWjy"}},{"cell_type":"code","source":["def adv_plot_compare(obs_data_analysis, clim_data_analysis, data_type, out_path):\n","    # 1) difference between model and observations\n","    dif = clim_data_analysis - obs_data_analysis\n","\n","    # 2) print summary statistics of each dataset------------------------------\n","    obs_mean = float(obs_data_analysis.mean())  # save mean and stdev for use in calculating test statistics {res:.3e}\n","    obs_stdev = float(obs_data_analysis.std())\n","    obs_min = float(np.amin(obs_data_analysis))\n","    obs_max = float(np.amax(obs_data_analysis))\n","\n","    clim_mean = float(clim_data_analysis.mean())\n","    clim_stdev = float(clim_data_analysis.std())\n","    clim_min = float(np.amin(clim_data_analysis))\n","    clim_max = float(np.amax(clim_data_analysis))\n","\n","    dif_mean = float(dif.mean())\n","    dif_stdev = float(dif.std())\n","    dif_min = float(dif.min())\n","    dif_max = float(dif.max())\n","\n","    # 3) plot difference averaged over all time in data------------------------\n","    dif_avg = dif.mean(dim='time')\n","    clim_data_mean = clim_data_analysis.mean(dim='time')\n","    obs_data_mean = obs_data_analysis.mean(dim='time')\n","\n","    lon_step = dif_avg.lon[2] - dif_avg.lon[1]\n","    lon_min = min(dif_avg.lon)\n","    lon_max = max(dif_avg.lon)\n","\n","    field_std = clim_data_mean.std()\n","    field_mean = clim_data_mean.mean()\n","    dif_std = dif_avg.std()\n","    lev1 = np.linspace(-dif_std*2, dif_std*2, 10)\n","    lev2 = np.linspace(field_mean-2*field_std, field_mean+2*field_std, 10)\n","    cmap1 = plt.cm.RdBu_r\n","\n","\n","    if (lon_max - lon_min + lon_step)/lon_step == len(dif_avg.lon):  # check if␣longitudes are continuous, if there is no gap plot across as usual (central longitude = 0)\n","        fig = plt.figure(figsize=[8, 10])\n","        proj = ccrs.PlateCarree(central_longitude=0)\n","        ax1 = fig.add_subplot(3, 1, 3, projection=proj)\n","        dif_avg.plot.contourf(ax=ax1, transform=ccrs.PlateCarree(), cmap=cmap1, levels=lev1, extend='both')\n","        ax1.coastlines()\n","        ax1.text(35,85,f'Diff Mean: {dif_mean:.2e}')\n","        ax1.text(35,80, f'Diff Std: {dif_stdev:.2e}')\n","        ax1.text(35,75, f'Diff Min: {dif_min:.2e}')\n","        ax1.text(35,70, f'Diff Max: {dif_max:.2e}')\n","        plt.title('Average Difference Between Model and Observations: {}'.format(var_name))\n","\n","        ax2 = fig.add_subplot(3, 1, 2, projection=proj)\n","        clim_data_mean.plot.contourf(ax=ax2, transform=ccrs.PlateCarree(), cmap=cmap1, levels=lev2, extend='both')\n","        ax2.coastlines()\n","        ax2.text(35,85, f'Model Mean: {clim_mean:.2e}')\n","        ax2.text(35,80, f'Model Std: {clim_stdev:.2e}')\n","        plt.title('Average Model Field: {}'.format(var_name))\n","\n","        ax3 = fig.add_subplot(3, 1, 1, projection=proj)\n","        obs_data_mean.plot.contourf(ax=ax3, transform=ccrs.PlateCarree(), cmap=cmap1, levels=lev2, extend='both')\n","        ax3.coastlines()\n","        ax3.text(35,85, f'Obs Mean: {obs_mean:.2e}')\n","        ax3.text(35,80, f'Obs Std: {obs_stdev:.2e}')\n","        plt.title('Average Observation Field: {}'.format(var_name))\n","        plt.savefig(os.path.join(out_path, data_type+'_AvgDifMap'))\n","        plt.show()\n","    else:   # if longitudes are not continuous, plot with 180 as central longitude instead\n","      new_lon = np.zeros(len(dif_avg.lon))\n","      for i in range(0, len(dif_avg.lon)):\n","        if dif_avg.lon[i] < 0:\n","          new_lon[i] = dif_avg.lon[i] % 180\n","        else:\n","          new_lon[i] = dif_avg.lon[i] - 180\n","      lc = new_lon.max() + 35\n","      dif_avg['lon'] = new_lon\n","      cm = 180\n","      proj = ccrs.PlateCarree(central_longitude=cm)\n","      fig = plt.figure(figsize = [20,5])\n","      ax1 = fig.add_subplot(3, 1, 3, projection=proj)\n","      dif_avg.plot.contourf(ax=ax1, cmap=cmap1, levels=lev1, extend='both')\n","      ax1.text(lc,85,f'Diff Mean: {dif_mean:.2e}')\n","      ax1.text(lc,80, f'Diff Std: {dif_stdev:.2e}')\n","      ax1.text(lc,75, f'Diff Min: {dif_min:.2e}')\n","      ax1.text(lc,70, f'Diff Max: {dif_max:.2e}')\n","      ax1.coastlines()\n","      ax1.gridlines(draw_labels=True, crs=ccrs.PlateCarree())\n","      plt.title('Average Difference Between Model and Observations: {}'.format(var_name))\n","\n","      clim_data_mean['lon'] = new_lon\n","      cm = 180\n","      proj = ccrs.PlateCarree(central_longitude=cm)\n","      fig = plt.figure(figsize = [20,5])\n","      ax2 = fig.add_subplot(3, 1, 2, projection=proj)\n","      clim_data_mean.plot.contourf(ax=ax2, cmap=cmap1, levels=lev2, extend='both')\n","      ax2.text(lc,85,f'Model Mean: {clim_mean:.2e}')\n","      ax2.text(lc,80, f'Model Std: {clim_stdev:.2e}')\n","      ax2.coastlines()\n","      ax2.gridlines(draw_labels=True, crs=ccrs.PlateCarree())\n","      plt.title('Average Model Field: {}'.format(var_name))\n","\n","      obs_data_mean['lon'] = new_lon\n","      cm = 180\n","      proj = ccrs.PlateCarree(central_longitude=cm)\n","      fig = plt.figure(figsize = [20,5])\n","      ax3 = fig.add_subplot(3, 1, 1, projection=proj)\n","      obs_data_mean.plot.contourf(ax=ax3, cmap=cmap1, levels=lev2, extend='both')\n","      ax3.text(lc,85,f'Obs Mean: {obs_mean:.2e}')\n","      ax3.text(lc,80, f'Obs Std: {obs_stdev:.2e}')\n","      ax3.coastlines()\n","      ax3.gridlines(draw_labels=True, crs=ccrs.PlateCarree())\n","      plt.title('Average Observation Field: {}'.format(var_name))\n","      plt.savefig(os.path.join(out_path, data_type+'_AvgDifMap'))\n","      plt.show()\n","\n","    # 4) plot histogram of each------------------------------------------------\n","    plt.figure(figsize=(9, 5))\n","    clim_data_analysis.plot.hist(bins=100, color='r', alpha=0.5, label='Model Data')\n","    obs_data_analysis.plot.hist(bins=100, color='k', alpha=0.5, label='Observational Data')\n","    plt.legend()\n","    plt.ylabel('Count')\n","    plt.title('Distribution of Model Predictions vs Observations: {}'.format(var_name))\n","    #plt.xlim([-0.001, 0.1])   #----- add axis limits if desired\n","    #plt.ylim([0, 2*10**6])\n","    plt.savefig(os.path.join(out_path, data_type+'_2Hist'))\n","    plt.show()\n","\n","    # 5) plot histogram of differences-----------------------------------------\n","    plt.figure(figsize=(9, 5))\n","    dif.plot.hist(bins=100, color='b', alpha = 0.5, label = 'Data')\n","    plt.axvline(x = 0, color = 'r', alpha = 0.5, label = 'Zero')\n","    plt.legend()\n","    plt.ylabel('Count')\n","    plt.title('Distribution of Differences Between Model Predictions and Observations: {}'.format(var_name))\n","    #plt.xlim([-0.1, 0.1])   #----- add axis limits if desired\n","    #plt.ylim([0, 0.6*10**6])\n","    plt.savefig(os.path.join(out_path, data_type+'_DifHist'))\n","    plt.show()\n","\n","    # 6) plot timeseries of each\n","    obs_ts = obs_data_analysis.mean(dim='lat').mean(dim='lon')\n","    clim_ts = clim_data_analysis.mean(dim='lat').mean(dim='lon')\n","    plt.figure(figsize=(15, 10))\n","    obs_ts.plot(color='b', alpha=0.5, label='Observational Data Mean')\n","    clim_ts.plot(color='r', alpha=0.5, label='Climate Model Data Mean')\n","    plt.legend()\n","    plt.title('Timeseries of Mean for Climate Model and Observational Data: {}'.format(var_name))\n","    plt.savefig(os.path.join(out_path, data_type+'_2TS'))\n","    plt.show()\n","\n","    # 7) plot timeseries of difference\n","    dif_ts = (clim_data_analysis - obs_data_analysis).mean(dim='lat').mean(dim='lon')\n","    plt.figure(figsize=(15,10))\n","    dif_ts.plot(color='b', label='Data')\n","    plt.axhline(y=0, color='r', label='Zero')\n","    plt.title('Timeseries of Difference Between Climate Model and Observational Data: {}'.format(var_name))\n","    plt.savefig(os.path.join(out_path, data_type+'_DifTS'))\n","    plt.show()\n","\n","    # 8) T-test to determine if difference is different than 0-----------------\n","    n = len(dif.lat) * len(dif.lon) * len(dif.time)\n","    T_stat = float((dif_mean - 0)/(dif_stdev/np.sqrt(n)))\n","    T_p_val = float(stats.t.sf(abs(T_stat), n-1))\n","\n","    # 9) F-test to detemine if variances are statistically different from each other\n","    obs_var_full = float(obs_data_analysis.var(skipna=True))\n","    clim_var_full = float(clim_data_analysis.var(skipna=True))\n","    obs_var_space = float((obs_data_analysis.mean(dim='time').std())**2)\n","    clim_var_space = float((clim_data_analysis.mean(dim='time').std())**2)\n","    obs_var_time = obs_data_analysis.var(dim='time', skipna=True)\n","    clim_var_time = clim_data_analysis.var(dim='time', skipna=True)\n","    obs_var_time_avg = float(obs_var_time.mean())\n","    clim_var_time_avg = float(clim_var_time.mean())\n","\n","    obs_n_full = float(obs_data_analysis.count())\n","    clim_n_full = float(clim_data_analysis.count())\n","    obs_n_space = float(obs_data_analysis.mean(dim='time').count())\n","    clim_n_space = float(clim_data_analysis.mean(dim='time').count())\n","    obs_n_time = float(obs_data_analysis.time.count())\n","    clim_n_time = float(clim_data_analysis.time.count())\n","\n","    F_stat_full = float(obs_var_full/clim_var_full)\n","    F_p_val_full = float(1-stats.f.cdf(F_stat_full, obs_n_full-1, clim_n_full-1))\n","    F_stat_space = float(obs_var_space/clim_var_space)\n","    F_p_val_space = float(1-stats.f.cdf(F_stat_space, obs_n_space-1, clim_n_space-1))\n","    F_stat_time = float(obs_var_time_avg/clim_var_time_avg)\n","    F_p_val_time = float(1-stats.f.cdf(F_stat_time, obs_n_time-1, clim_n_time-1))\n","\n","\n","    # 10) Find mean squared error-----------------------------------------------\n","    mse = float(np.square(np.subtract(obs_data_analysis, clim_data_analysis)).mean())\n","    rmse = float(np.sqrt(mse))\n","\n","    return(obs_mean, obs_stdev, obs_min, obs_max, obs_var_full, obs_var_space, obs_var_time_avg,\n","           clim_mean, clim_stdev, clim_min, clim_max, clim_var_full, clim_var_space, clim_var_time_avg,\n","           dif_mean, dif_stdev, dif_min, dif_max,\n","           mse, rmse,\n","           F_stat_full, F_stat_space, F_stat_time, F_p_val_full, F_p_val_space, F_p_val_time,\n","           T_stat, T_p_val)"],"metadata":{"id":"nm6jwOehOp5J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Combine all of the functions\n","**Description:** Combines the time_match(), space_match(), mask_fun(), and plot_compare() functions to do all of the temporal and spatial extent and resolution matching as well as the masking and model comparison in one step.  \n","**Input Data:** Observational data and climate model data with the same temporal resolution (hourly, daily, monthly, etc.) that have already been compressed down to one file using the Script4DataExtraction notebook or python script.  \n","**Outputs:** Ascii file containing all of the statistical analysis for the model comparison.  \n","**Process:**  \n","1. Runs the data through each of the time_match(), space_match(), mask_fun(), and plot_compare() functions in order  \n","2. Compiles all of the outputs from plot_compare into a table with columns of the name of the statistic/statistical test, and the values for each for the full comparison, comparison over land only, and comparison over ocean only.  \n","3. Writes the statistical table to an ascii file."],"metadata":{"id":"1E_8Q0qMom9D"}},{"cell_type":"code","source":["def mod_compare(obs_data, clim_data, out_path):\n","    # 1) run original data through all of the analysis functions\n","    obs_data_tc, clim_data_tc = time_match(obs_data, clim_data, '%Y-%m')\n","    print('Temporal correction complete.')  # just for indication that program is progressing\n","    obs_data_analysis, clim_data_analysis = space_match(obs_data_tc, clim_data_tc)\n","    print('Spatial correction complete.')  # just for indication that program is progressing\n","    obs_land, obs_ocean, clim_land, clim_ocean = mask_fun(obs_data_analysis, clim_data_analysis, mask)\n","    print('Ocean/Land masking complete.')  # just for indication that program is progressing\n","\n","    (full_obs_mean, full_obs_stdev, full_obs_min, full_obs_max, full_obs_var_full, full_obs_var_space, full_obs_var_time,\n","      full_clim_mean, full_clim_stdev, full_clim_min, full_clim_max, full_clim_var_full, full_clim_var_space, full_clim_var_time,\n","      full_dif_mean, full_dif_stdev, full_dif_min, full_dif_max, full_mse, full_rmse, full_F_stat_full, full_F_stat_space, full_F_stat_time,\n","      full_F_p_val_full, full_F_p_val_space, full_F_p_val_time, full_T_stat, full_T_p_val) = adv_plot_compare(obs_data_analysis, clim_data_analysis, 'full', out_path)\n","\n","    (land_obs_mean, land_obs_stdev, land_obs_min, land_obs_max, land_obs_var_full, land_obs_var_space, land_obs_var_time,\n","     land_clim_mean, land_clim_stdev, land_clim_min, land_clim_max, land_clim_var_full, land_clim_var_space, land_clim_var_time,\n","     land_dif_mean, land_dif_stdev, land_dif_min, land_dif_max, land_mse, land_rmse, land_F_stat_full, land_F_stat_space, land_F_stat_time,\n","     land_F_p_val_full, land_F_p_val_space, land_F_p_val_time, land_T_stat, land_T_p_val) = adv_plot_compare(obs_land, clim_land, 'land', out_path)\n","\n","    (ocean_obs_mean, ocean_obs_stdev, ocean_obs_min, ocean_obs_max, ocean_obs_var_full, ocean_obs_var_space, ocean_obs_var_time,\n","     ocean_clim_mean, ocean_clim_stdev, ocean_clim_min, ocean_clim_max, ocean_clim_var_full, ocean_clim_var_space, ocean_clim_var_time,\n","     ocean_dif_mean, ocean_dif_stdev, ocean_dif_min, ocean_dif_max, ocean_mse, ocean_rmse, ocean_F_stat_full, ocean_F_stat_space, ocean_F_stat_time,\n","     ocean_F_p_val_full, ocean_F_p_val_space, ocean_F_p_val_time, ocean_T_stat, ocean_T_p_val) = adv_plot_compare(obs_ocean, clim_ocean, 'ocean', out_path)\n","\n","    # 2) create a table with all of the statistics in one place\n","    full_stats = Table({'statistic': ['obs_mean', 'obs_stdev', 'obs_min', 'obs_max', 'obs_var_full', 'obs_var_space', 'obs_var_time_avg',\n","                                      'clim_mean', 'clim_stdev', 'clim_min', 'clim_max', 'clim_var_full', 'clim_var_space', 'clim_var_time_avg',\n","                                      'dif_mean', 'dif_stdev', 'dif_min', 'dif_max', 'mse', 'rmse', 'F_stat_full', 'F_stat_space', 'F_stat_time', 'F_p_val_full', 'F_p_val_space', 'F_p_val_time', 'T_stat', 'T_p_val'],\n","                    'Full stats': [f'{full_obs_mean:.2e}', f'{full_obs_stdev:.2e}', f'{full_obs_min:.2e}', f'{full_obs_max:.2e}', f'{full_obs_var_full:.2e}', f'{full_obs_var_space:.2e}', f'{full_obs_var_time:.2e}', f'{full_clim_mean:.2e}', f'{full_clim_stdev:.2e}', f'{full_clim_min:.2e}', f'{full_clim_max:.2e}', f'{full_clim_var_full:.2e}', f'{full_clim_var_space:.2e}', f'{full_clim_var_time:.2e}', f'{full_dif_mean:.2e}', f'{full_dif_stdev:.2e}', f'{full_dif_min:.2e}', f'{full_dif_max:.2e}', f'{full_mse:.2e}', f'{full_rmse:.2e}', f'{full_F_stat_full:.2e}', f'{full_F_stat_space:.2e}', f'{full_F_stat_time:.2e}', f'{full_F_p_val_full:.2e}', f'{full_F_p_val_space:.2e}', f'{full_F_p_val_time:.2e}', f'{full_T_stat:.2e}', f'{full_T_p_val:.2e}'],\n","                    'Land stats': [f'{land_obs_mean:.2e}', f'{land_obs_stdev:.2e}', f'{land_obs_min:.2e}', f'{land_obs_max:.2e}', f'{land_obs_var_full:.2e}', f'{land_obs_var_space:.2e}', f'{land_obs_var_time:.2e}', f'{land_clim_mean:.2e}', f'{land_clim_stdev:.2e}', f'{land_clim_min:.2e}', f'{land_clim_max:.2e}', f'{land_clim_var_full:.2e}', f'{land_clim_var_space:.2e}', f'{land_clim_var_time:.2e}', f'{land_dif_mean:.2e}', f'{land_dif_stdev:.2e}', f'{land_dif_min:.2e}', f'{land_dif_max:.2e}', f'{land_mse:.2e}', f'{land_rmse:.2e}', f'{land_F_stat_full:.2e}', f'{land_F_stat_space:.2e}', f'{land_F_stat_time:.2e}', f'{land_F_p_val_full:.2e}', f'{land_F_p_val_space:.2e}', f'{land_F_p_val_time:.2e}', f'{land_T_stat:.2e}', f'{land_T_p_val:.2e}'],\n","                    'Ocean stats': [f'{ocean_obs_mean:.2e}', f'{ocean_obs_stdev:.2e}', f'{ocean_obs_min:.2e}', f'{ocean_obs_max:.2e}', f'{ocean_obs_var_full:.2e}', f'{ocean_obs_var_space:.2e}', f'{ocean_obs_var_time:.2e}', f'{ocean_clim_mean:.2e}', f'{ocean_clim_stdev:.2e}', f'{ocean_clim_min:.2e}', f'{ocean_clim_max:.2e}', f'{ocean_clim_var_full:.2e}', f'{ocean_clim_var_space:.2e}', f'{ocean_clim_var_time:.2e}', f'{ocean_dif_mean:.2e}', f'{ocean_dif_stdev:.2e}', f'{ocean_dif_min:.2e}', f'{ocean_dif_max:.2e}', f'{ocean_mse:.2e}', f'{ocean_rmse:.2e}', f'{ocean_F_stat_full:.2e}', f'{ocean_F_stat_space:.2e}', f'{ocean_F_stat_time:.2e}', f'{ocean_F_p_val_full:.2e}', f'{ocean_F_p_val_space:.2e}', f'{ocean_F_p_val_time:.2e}', f'{ocean_T_stat:.2e}', f'{ocean_T_p_val:.2e}']},\n","                   names=['statistic', 'Full stats', 'Land stats', 'Ocean stats'])\n","    # 3)\n","    ascii.write(full_stats, os.path.join(out_path, 'full_stats.txt'), overwrite=True)\n","    full_stats.pprint(max_lines=-1, max_width=-1)\n","    return(full_stats)"],"metadata":{"id":"d_nEMnRJchhP"},"execution_count":null,"outputs":[]}]}